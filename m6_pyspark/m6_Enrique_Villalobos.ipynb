{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import urllib\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.types import StructType, StructField, DoubleType, StringType, IntegerType, NumericType\n",
    "from pyspark.ml.feature import Imputer,  StringIndexer, OneHotEncoder, VectorAssembler, MinMaxScaler\n",
    "from pyspark.sql.functions import col, sum\n",
    "\n",
    "from pyspark.ml.regression import DecisionTreeRegressor\n",
    "from pyspark.ml.classification import MultilayerPerceptronClassifier\n",
    "\n",
    "\n",
    "from pyspark.ml.evaluation import RegressionEvaluator, MulticlassClassificationEvaluator\n",
    "\n",
    "\n",
    "from pyspark.ml import Pipeline\n",
    "\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "\n",
    "from pprint import pprint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder.appName(\"regresion_diamonds\").getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "schema = StructType([\n",
    "    StructField(\"carat\", DoubleType(), True),\n",
    "    StructField(\"cut\", StringType(), True),\n",
    "    StructField(\"color\", StringType(), True),\n",
    "    StructField(\"clarity\", StringType(), True),\n",
    "    StructField(\"depth\", DoubleType(), True),\n",
    "    StructField(\"table\", DoubleType(), True),\n",
    "    StructField(\"price\", IntegerType(), True),\n",
    "    StructField(\"x\", DoubleType(), True),\n",
    "    StructField(\"y\", DoubleType(), True),\n",
    "    StructField(\"z\", DoubleType(), True)\n",
    "])\n",
    "\n",
    "url = \"https://raw.githubusercontent.com/mwaskom/seaborn-data/refs/heads/master/diamonds.csv\"\n",
    "local_path = \"/tmp/diamonds.csv\"\n",
    "\n",
    "urllib.request.urlretrieve(url, local_path)\n",
    "\n",
    "df = spark.read.format(\"csv\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .schema(schema) \\\n",
    "    .load(local_path)\n",
    "\n",
    "\n",
    "df.show(5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "root\n",
      " |-- carat: double (nullable = true)\n",
      " |-- cut: string (nullable = true)\n",
      " |-- color: string (nullable = true)\n",
      " |-- clarity: string (nullable = true)\n",
      " |-- depth: double (nullable = true)\n",
      " |-- table: double (nullable = true)\n",
      " |-- price: integer (nullable = true)\n",
      " |-- x: double (nullable = true)\n",
      " |-- y: double (nullable = true)\n",
      " |-- z: double (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## prediccion price"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "label_col = 'price'\n",
    "numerical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "categorical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat_imputed', 'depth_imputed', 'table_imputed', 'price_imputed', 'x_imputed', 'y_imputed', 'z_imputed']\n"
     ]
    }
   ],
   "source": [
    "# variables numericas imputadas con media\n",
    "imputer_numerical = Imputer(\n",
    "    inputCols=numerical_cols,\n",
    "    outputCols=[c + '_imputed' for c in numerical_cols],\n",
    "    strategy='median'\n",
    ")\n",
    "numerical_cols_imputed = [c + '_imputed' for c in numerical_cols]\n",
    "print(numerical_cols_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assembler_numerical = VectorAssembler(\n",
    "    inputCols=numerical_cols_imputed,\n",
    "    outputCol='numeric_features'\n",
    ")\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol='numeric_features',\n",
    "    outputCol='numeric_features_scaled'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed', 'color_indexed', 'clarity_indexed']\n"
     ]
    }
   ],
   "source": [
    "# variables categoricas\n",
    "indexers_features = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + '_indexed', handleInvalid='keep') for c in categorical_cols\n",
    "]\n",
    "categorical_cols_indexed = [c + '_indexed' for c in categorical_cols]\n",
    "print(categorical_cols_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed_imputed', 'color_indexed_imputed', 'clarity_indexed_imputed']\n"
     ]
    }
   ],
   "source": [
    "imputer_categorical = Imputer(\n",
    "    inputCols=categorical_cols_indexed,\n",
    "    outputCols=[c + '_imputed' for c in categorical_cols_indexed],\n",
    "    strategy='mode'\n",
    ")\n",
    "categorical_cols_indexed_imputed = [c + '_imputed' for c in categorical_cols_indexed]\n",
    "print(categorical_cols_indexed_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['cut_indexed_imputed_onehot', 'color_indexed_imputed_onehot', 'clarity_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "encoders_onehot = [\n",
    "    OneHotEncoder(inputCol=c, outputCol=c + '_onehot') \n",
    "    for c in categorical_cols_indexed_imputed\n",
    "]\n",
    "categorical_cols_onehot = [c + '_onehot' for c in categorical_cols_indexed_imputed]\n",
    "print(categorical_cols_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numeric_features_scaled', 'cut_indexed_imputed_onehot', 'color_indexed_imputed_onehot', 'clarity_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "#todo df\n",
    "all_columns = ['numeric_features_scaled'] + categorical_cols_onehot\n",
    "print(all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "assembler_all = VectorAssembler(\n",
    "    inputCols=all_columns,\n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#modelo\n",
    "regresor_decisiontree = DecisionTreeRegressor(seed=42, labelCol=label_col)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# particionamiento de datos\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "pipeline = Pipeline(stages = [\n",
    "    \n",
    "    *indexers_features,\n",
    "    imputer_categorical,\n",
    "    *encoders_onehot,\n",
    "    imputer_numerical,\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    assembler_all,\n",
    "    regresor_decisiontree\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenamos y predecimos\n",
    "pipeline_model = pipeline.fit(df_train)\n",
    "df_pred_price = pipeline_model.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>modelo</th>\n",
       "      <th>r2</th>\n",
       "      <th>mae</th>\n",
       "      <th>mse</th>\n",
       "      <th>rmse</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>DecisionTreeRegressor</td>\n",
       "      <td>0.994727</td>\n",
       "      <td>168.17409</td>\n",
       "      <td>85786.051188</td>\n",
       "      <td>292.892559</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  modelo        r2        mae           mse        rmse\n",
       "0  DecisionTreeRegressor  0.994727  168.17409  85786.051188  292.892559"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#evaluamos\n",
    "\n",
    "evaluator_r2 = RegressionEvaluator(metricName='r2', labelCol=label_col)\n",
    "evaluator_mae = RegressionEvaluator(metricName='mae', labelCol=label_col)\n",
    "evaluator_mse = RegressionEvaluator(metricName='mse', labelCol=label_col)\n",
    "evaluator_rmse = RegressionEvaluator(metricName='rmse', labelCol=label_col)\n",
    "\n",
    "\n",
    "r2_ = evaluator_r2.evaluate(df_pred_price)\n",
    "mae_ = evaluator_mae.evaluate(df_pred_price)\n",
    "mse_= evaluator_mse.evaluate(df_pred_price)\n",
    "rmse_= evaluator_rmse.evaluate(df_pred_price)\n",
    "\n",
    "metrics = {\n",
    "    \"modelo\": [\"DecisionTreeRegressor\"], \n",
    "    \"r2\": [r2_],\n",
    "    \"mae\": [mae_],\n",
    "    \"mse\": [mse_],\n",
    "    \"rmse\": [rmse_]\n",
    "}\n",
    "\n",
    "# Convertir el diccionario a un DataFrame de pandas\n",
    "df_price = pd.DataFrame(metrics)\n",
    "df_price\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Clasificacion de cut con  MultiLayerPerceptronClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "|carat|    cut|color|clarity|depth|table|price|   x|   y|   z|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "| 0.23|  Ideal|    E|    SI2| 61.5| 55.0|  326|3.95|3.98|2.43|\n",
      "| 0.21|Premium|    E|    SI1| 59.8| 61.0|  326|3.89|3.84|2.31|\n",
      "| 0.23|   Good|    E|    VS1| 56.9| 65.0|  327|4.05|4.07|2.31|\n",
      "| 0.29|Premium|    I|    VS2| 62.4| 58.0|  334| 4.2|4.23|2.63|\n",
      "| 0.31|   Good|    J|    SI2| 63.3| 58.0|  335|4.34|4.35|2.75|\n",
      "+-----+-------+-----+-------+-----+-----+-----+----+----+----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|carat|cut|color|clarity|depth|table|price|  x|  y|  z|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "|    0|  0|    0|      0|    0|    0|    0|  0|  0|  0|\n",
      "+-----+---+-----+-------+-----+-----+-----+---+---+---+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "df = df.dropna(subset=['cut'])\n",
    "\n",
    "# contar nulos\n",
    "df.select([sum(col(c).isNull().cast('int')).alias(c) for c in df.columns]).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocesados\n",
    "label_col = 'cut'\n",
    "numerical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, NumericType)]\n",
    "categorical_cols = [field.name for field in df.schema.fields if isinstance(field.dataType, StringType) and field.name != label_col]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "indexer_label = StringIndexer(\n",
    "    inputCol=label_col,\n",
    "    outputCol='label',\n",
    "    handleInvalid='keep'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color_indexed', 'clarity_indexed']\n"
     ]
    }
   ],
   "source": [
    "#categoricas indexadas\n",
    "indexers_features = [\n",
    "    StringIndexer(inputCol=c, outputCol=c + '_indexed', handleInvalid='keep') for c in categorical_cols\n",
    "]\n",
    "categorical_cols_indexed = [c + '_indexed' for c in categorical_cols]\n",
    "print(categorical_cols_indexed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color_indexed_imputed', 'clarity_indexed_imputed']\n"
     ]
    }
   ],
   "source": [
    "#categoricad imputadas con moda\n",
    "imputer_categorical = Imputer(\n",
    "    inputCols=categorical_cols_indexed,\n",
    "    outputCols=[c + '_imputed' for c in categorical_cols_indexed],\n",
    "    strategy='mode'\n",
    ")\n",
    "categorical_cols_indexed_imputed = [c + '_imputed' for c in categorical_cols_indexed]\n",
    "print(categorical_cols_indexed_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['color_indexed_imputed_onehot', 'clarity_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "# one hot encoders para las categóricas indexadas imputadas\n",
    "encoders_onehot = [\n",
    "    OneHotEncoder(inputCol=c, outputCol=c + '_onehot') \n",
    "    for c in categorical_cols_indexed_imputed\n",
    "]\n",
    "categorical_cols_onehot = [c + '_onehot' for c in categorical_cols_indexed_imputed]\n",
    "print(categorical_cols_onehot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['carat_imputed', 'depth_imputed', 'table_imputed', 'price_imputed', 'x_imputed', 'y_imputed', 'z_imputed']\n"
     ]
    }
   ],
   "source": [
    "#variables numericas imputadas con media\n",
    "imputer_numerical = Imputer(\n",
    "    inputCols=numerical_cols,\n",
    "    outputCols=[c + '_imputed' for c in numerical_cols],\n",
    "    strategy='median'\n",
    ")\n",
    "numerical_cols_imputed = [c + '_imputed' for c in numerical_cols]\n",
    "print(numerical_cols_imputed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "assembler_numerical = VectorAssembler(\n",
    "    inputCols=numerical_cols_imputed,\n",
    "    outputCol='numeric_features'\n",
    ")\n",
    "scaler = MinMaxScaler(\n",
    "    inputCol='numeric_features',\n",
    "    outputCol='numeric_features_scaled'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['numeric_features_scaled', 'color_indexed_imputed_onehot', 'clarity_indexed_imputed_onehot']\n"
     ]
    }
   ],
   "source": [
    "all_columns = ['numeric_features_scaled'] + categorical_cols_onehot\n",
    "print(all_columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#unimos tods las features sin cut\n",
    "assembler_all = VectorAssembler(\n",
    "    inputCols=all_columns,\n",
    "    outputCol='features'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pìpeline\n",
    "pipeline_cut = Pipeline(stages = [\n",
    "\n",
    "    indexer_label,\n",
    "    *indexers_features,\n",
    "    imputer_categorical,\n",
    "    *encoders_onehot,\n",
    "    imputer_numerical,\n",
    "    assembler_numerical,\n",
    "    scaler,\n",
    "    assembler_all\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#split\n",
    "df_train, df_test = df.randomSplit([0.8, 0.2], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "_with_features = pipeline_cut.fit(df_train)\n",
    "df_train_transformed = _with_features.transform(df_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "neuronas entrada: 20, neuronas salida: 5, neuronas capas ocultas: [5, 4]\n"
     ]
    }
   ],
   "source": [
    "#parametrol del mlp\n",
    "num_features = df_train_transformed.first()['features'].size\n",
    "num_classes = df_train_transformed.select(\"label\").distinct().count()\n",
    "\n",
    "layers = [num_features, 5, 4, num_classes] #dos capas oculñtas de 5 y 4 neuronas\n",
    "\n",
    "print(f\"neuronas entrada: {num_features}, neuronas salida: {num_classes}, neuronas capas ocultas: {layers[1:-1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#modelo mlp\n",
    "\n",
    "\n",
    "mlp = MultilayerPerceptronClassifier(\n",
    "    featuresCol=\"features\",\n",
    "    labelCol=\"label\",\n",
    "    maxIter=100,\n",
    "    layers=layers,\n",
    "    blockSize=128,\n",
    "    seed=1234\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pipeline completo\n",
    "pipeline_cut_fin = Pipeline(stages=[pipeline_cut] + [mlp])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#entrenar y predecir\n",
    "pipeline_model_fin_cut = pipeline_cut_fin.fit(df_train)\n",
    "\n",
    "df_pred = pipeline_model_fin_cut.transform(df_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy 0.5538362346872985\n",
      "f1 0.4676510998719835\n",
      "precision 0.4762104055664424\n",
      "recall 0.5538362346872986\n"
     ]
    }
   ],
   "source": [
    "#evaluamos\n",
    "evaluator_accuracy = MulticlassClassificationEvaluator(metricName='accuracy')\n",
    "evaluator_f1 = MulticlassClassificationEvaluator(metricName='f1')\n",
    "evaluator_precision = MulticlassClassificationEvaluator(metricName='weightedPrecision')\n",
    "evaluator_recall = MulticlassClassificationEvaluator(metricName='weightedRecall')\n",
    "\n",
    "\n",
    "print('accuracy', evaluator_accuracy.evaluate(df_pred))\n",
    "print('f1', evaluator_f1.evaluate(df_pred))\n",
    "print('precision', evaluator_precision.evaluate(df_pred))\n",
    "print('recall', evaluator_recall.evaluate(df_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GridSearch con CV sobre clasificación de cut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# hiperaámetros a probar\n",
    "paramGrid = (ParamGridBuilder()\n",
    "             .addGrid(mlp.maxIter, [100, 200])  \n",
    "             .addGrid(mlp.layers, [\n",
    "                 [num_features, 5, 4, num_classes], \n",
    "                 [num_features, 8, 6, num_classes]   \n",
    "             ])\n",
    "             .build())\n",
    "\n",
    "evaluator = MulticlassClassificationEvaluator(\n",
    "    labelCol=\"label\", \n",
    "    predictionCol=\"prediction\", \n",
    "    metricName=\"accuracy\"\n",
    ")\n",
    "\n",
    "crossval = CrossValidator(\n",
    "    estimator=pipeline_cut_fin,\n",
    "    estimatorParamMaps=paramGrid,\n",
    "    evaluator=evaluator,\n",
    "    numFolds=6,\n",
    "    seed=42\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.688588007736944\n"
     ]
    }
   ],
   "source": [
    "#entrenamiento y predicción\n",
    "cvModel = crossval.fit(df_train)\n",
    "\n",
    "df_pred = cvModel.transform(df_test)\n",
    "print(\"Accuracy:\", evaluator.evaluate(df_pred))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'MultilayerPerceptronClassifier_8cdcbc1003c3__blockSize': 128,\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__featuresCol': 'features',\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__labelCol': 'label',\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__maxIter': 200,\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__predictionCol': 'prediction',\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__probabilityCol': 'probability',\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__rawPredictionCol': 'rawPrediction',\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__seed': 1234,\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__solver': 'l-bfgs',\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__stepSize': 0.03,\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__tol': 1e-06,\n",
       " 'MultilayerPerceptronClassifier_8cdcbc1003c3__layers': [20, 8, 6, 5]}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mejor modelo\n",
    "\n",
    "best_model = cvModel.bestModel.stages[-1]\n",
    "param_map = best_model.extractParamMap()\n",
    "\n",
    "param_dict = {str(param): value for param, value in param_map.items()}\n",
    "\n",
    "param_dict"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
